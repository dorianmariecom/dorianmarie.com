<!doctype html>
<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Le Language de Cent-Ans</title>
    <link href="/css/application.css" rel="stylesheet" media="all" />
    <link href="/css/rouge.css" rel="stylesheet" media="all" />
  </head>
  <body class="mx-auto max-w-4xl p-4 pt-16 prose">
    <p>
      <a href="/">dorianmarie.com</a>
      |
      <a href="/paulgraham">Paul Graham</a>
      |
      <a href="/legal">Legal</a>
      |
      <a href="/terms">Terms</a>
      |
      <a href="/privacy">Privacy</a>
    </p>
    <h1>Le Language de Cent-Ans</h1>
    <p>Chapitre 11</p>

    <p>
      Il est difficile de prédire à quoi ressemblera la vie dans cent ans. Il
      n’y a que quelques choses que nous pouvons dire avec certitude. Nous
      savons que tout le monde conduira des voitures volantes, que les lois de
      zonage seront assouplies pour permettre aux bâtiments de plusieurs
      centaines d’étages, qu’il fera nuit la plupart du temps et que les femmes
      seront toutes formées aux arts martiaux. Ici, je veux zoomer sur un détail
      de cette image. Quel type de langage de programmation utiliseront-ils pour
      écrire le logiciel contrôlant ces voitures volantes ?
    </p>

    <p>
      Cela vaut la peine d’y penser, non pas tant que nous utiliserons
      effectivement ces langages que parce que, si nous avons de la chance, nous
      utilisons des langages sur le chemin qui mène d’un point à un autre.
    </p>

    <p>
      Je pense que, comme les espèces, les langues formeront des arbres
      évolutifs, avec des impasses qui se ramifient partout. Nous pouvons déjà
      voir cela se produire. Cobol, malgré sa popularité, ne semble pas avoir de
      descendance intellectuelles. C’est une impasse évolutive, une langue
      néandertale.
    </p>

    <p>
      Je prédis un futur similaire pour Java. Les gens m’envoient parfois des
      courriels en disant : “Comment pouvez-vous dire que Java ne s’est pas
      révélé être un langage réussi ? C’est déjà un langage à succès. » Et
      j’admets que c’est le cas, si vous mesurez le succès par l’espace
      d’étagère occupé par les livres dessus, ou par le nombre d’ étudiants de
      premier cycle qui croient qu’ils doivent l’apprendre pour obtenir un
      emploi. Quand je dis que Java ne s’est pas révélé être un langage réussi,
      je veux dire quelque chose de plus spécifique : que Java s’est révélé être
      une impasse évolutive, comme Cobol.
    </p>

    <p>
      Ce n’est qu’une supposition. Je me trompe peut-être. Mon but ici n’est pas
      de casser Java, mais de soulever la question des arbres évolutifs et d’
      amener les gens à se demander, où sur l’arbre se trouve le langage x ? La
      raison de poser cette question n’est pas seulement pour que dans cent ans,
      nos fantômes puissent dire, je vous l’ai dit. C’est parce que rester près
      des branches principales est une heuristique utile pour trouver des
      langages qui seront bons à programmer maintenant.
    </p>

    <p>
      À tout moment, vous serez probablement le plus heureux sur les branches
      principales d’un arbre évolutif. Même quand il y avait encore beaucoup de
      Néandertaliens, il a dû être nul d’en être un. Les Cro-Magnons auraient
      constamment été en train de venir se battre avec vous et de voler votre
      nourriture.
    </p>

    <p>
      La raison pour laquelle je veux savoir à quoi ressembleront les langages
      dans cent ans, c’est pour savoir sur quelle branche de l’arbre parier
      maintenant.
    </p>

    <p>
      L’évolution des langages diffère de l’évolution des espèces parce que les
      branches peuvent converger. La branche de Fortran, par exemple, semble
      fusionner avec les descendants d’Algol. En théorie, c’est possible pour
      les espèces aussi, mais c’est si peu probable que cela ne se soit
      probablement jamais produit.
    </p>

    <p>
      La convergence est plus probable pour les langages, en partie parce que
      l’espace des possibilités est plus petit, et en partie parce que les
      mutations ne sont pas aléatoires. Les concepteurs de langages intègrent
      délibérément des idées d’autres langages.
    </p>

    <p>
      Il est particulièrement utile pour les concepteurs de langages de
      réfléchir à l’évolution des langages de programmation qui est susceptible
      de mener, car ils peuvent se diriger en conséquence. Dans ce cas, « rester
      sur une branche principale » devient plus qu’un moyen de choisir un bon
      langage. Cela devient une heuristique pour prendre les bonnes décisions en
      matière de conception du langage.
    </p>

    <p>
      N’importe quel langage de programmation peut être divisé en deux
      parties<br />
      un ensemble d’opérateurs fondamentaux qui jouent le rôle d’axiomes, et le
      reste du langage, qui pourrait en principe être écrit en termes de ces
      opérateurs fondamentaux.
    </p>

    <p>
      Je pense que les opérateurs fondamentaux sont les facteurs les plus
      importants dans la survie à long terme d’un langage. Le reste, vous pouvez
      changer. C’est comme la règle selon laquelle lors de l’achat d’une maison,
      vous devez d’abord tenir compte de l’emplacement. Tout le reste, vous
      pouvez le réparer plus tard, mais vous ne pouvez pas réparer
      l’emplacement.
    </p>

    <p>
      Il est important non seulement que les axiomes soient bien choisis, mais
      aussi qu’il y en ait peu. Les mathématiciens ont toujours ressenti cela à
      propos des axiomes - moins il y en a, mieux c’est - et je pense qu’ils ont
      mis le doigt sur quelque chose.
    </p>

    <p>
      À tout le moins, il doit être utile d’examiner de près le noyau d’un
      langage pour voir s’il y a des axiomes qui pourraient être éliminés. J’ai
      trouvé dans ma longue carrière de bidouilleur que le croûtage élève le
      croûtage, et j’ai vu cela se produire dans les logiciels ainsi que sous
      les lits et dans les coins des chambres.
    </p>

    <p>
      J’ai l’impression que les branches principales de l’arbre évolutif passent
      par les langages qui ont les noyaux les plus petits et les plus propres.
      Plus vous pouvez écrire d’un langage en soi, mieux c’est.
    </p>

    <p>
      Bien sûr, je fais une grande supposition en demandant même à quoi
      ressembleront les langages de programmation dans cent ans. Écrirons-nous
      même des programmes dans cent ans ? Ne dirons-nous pas simplement aux
      ordinateurs ce que nous voulons qu’ils fassent ?
    </p>

    <p>
      Il n’y a pas eu beaucoup de progrès dans ce département jusqu’à présent.
      Je suppose que dans cent ans, les gens diront toujours aux ordinateurs
      quoi faire en utilisant des programmes que nous reconnaîtrions comme tels.
      Il peut y avoir des tâches que nous résolvons maintenant en écrivant des
      programmes et que dans cent ans, vous n’aurez pas à écrire des programmes
      à résoudre, mais je pense qu’il y aura encore beaucoup de programmation du
      type que nous faisons aujourd’hui.
    </p>

    <p>
      Il peut sembler présomptueux de penser que n’importe qui peut prédire à
      quoi ressemblera n’importe quelle technologie dans cent ans. Mais
      rappelons-nous que nous avons déjà près de cinquante ans d’histoire
      derrière nous. Regarder vers l’avenir cent ans est une idée saisissable
      lorsque nous considérons à quel point les langages ont évolué lentement au
      cours des cinquante dernières années.
    </p>

    <p>
      Les langages évoluent lentement parce qu’elles ne sont pas vraiment des
      technologies. Les langages sont la notation. Un programme est une
      description formelle du problème que vous voulez qu’un ordinateur résolve
      pour vous. Ainsi, le taux d’évolution dans les langages de programmation
      ressemble plus au taux d’évolution en notation mathématique que, par
      exemple, au transport ou aux communications. La notation mathématique
      évolue, mais pas avec les sauts géants que vous voyez dans la technologie.
    </p>

    <p>
      Quels que soient les ordinateurs dans cent ans, il semble sûr de prédire
      qu’ils seront beaucoup plus rapides. Si la loi de Moore continue de
      s’édifier, elle sera 74 quintillions (73 786 976 294 838 206 464) fois
      plus rapide. C’est un peu difficile à imaginer. Et en effet, la prédiction
      la plus probable dans le département de la vitesse est peut-être que la
      loi de Moore cessera de fonctionner. Tout ce qui est censé doubler tous
      les dix-huit mois semble susceptible de se heurter à une sorte de limite
      fondamentale. Mais je n’ai aucun mal à croire que les ordinateurs seront
      beaucoup plus rapides. Même s’ils finissent par être un million de fois
      plus rapides, cela devrait changer considérablement les règles de base
      pour les langages de programmation. Entre autres choses, il y aura plus de
      place pour ce qui serait maintenant considéré comme des langages lents,
      c’est-à-dire des langages qui ne donnent pas de code très efficace.
    </p>

    <p>
      Et pourtant, certaines applications exigeront toujours de la vitesse.
      Certains des problèmes que nous voulons résoudre avec les ordinateurs sont
      créés par des ordinateurs ; par exemple, la vitesse à laquelle vous devez
      traiter les images vidéo dépend de la vitesse à laquelle un autre
      ordinateur peut les générer. Et il y a une autre classe de problèmes qui
      ont intrinsèquement une capacité illimitée pour absorber les cycles : le
      rendu d’images, la cryptographie, les simulations.
    </p>

    <p>
      Si certaines applications peuvent être de plus en plus inefficaces tandis
      que d’autres continuent d’exiger toute la vitesse que le matériel peut
      offrir, des ordinateurs plus rapides signifieront que les langages devront
      couvrir un éventail toujours plus large d’efficacités. Nous avons déjà vu
      cela se produire. Les implémentations actuelles de certains nouveaux
      langages populaires sont étonnamment inutiles selon les normes des
      décennies précédentes.
    </p>

    <p>
      Ce n’est pas seulement quelque chose qui se passe avec les langages de
      programmation. C’est une tendance historique générale. Au fur et à mesure
      que les technologies s’améliorent, chaque génération peut faire des choses
      que la génération précédente aurait considérées comme du gaspillage. Il y
      a trente ans, les gens étaient étonnés de voir à quel point nous faisions
      des appels téléphoniques interurbains. Il y a cent ans, les gens seraient
      encore plus étonnés qu’un forfait voyage d’un jour de Boston à New York
      via Memphis existe.
    </p>

    <p>
      Je peux déjà vous dire ce qui va arriver à tous ces cycles supplémentaires
      que le matériel plus rapide va nous donner au cours des cent prochaines
      années. Ils vont presque tous être gaspillés.
    </p>

    <p>
      J’ai appris à programmer quand la puissance de l’ordinateur était rare. Je
      me souviens avoir pris tous les espaces de mes programmes de base pour
      qu’ils s’intègrent dans la mémoire d’un TRS-80 4K. L’idée de tous ces
      logiciels incroyablement inefficaces qui brûlent des cycles en faisant la
      même chose encore et encore me semble un peu grossière. Mais je pense que
      mes intuitions ici sont fausses. Je suis comme quelqu’un qui a grandi
      pauvre et qui ne supporte pas de dépenser de l’argent même pour quelque
      chose d’important, comme aller chez le médecin.
    </p>

    <p>
      Certains types de déchets sont vraiment dégoûtants. Les SUVs, par exemple,
      seraient sans doute grossiers même s’ils étaient alimentés par un
      carburant qui ne s’épuiserait jamais et ne générerait aucune pollution.
      Les SUVs sont grossiers parce qu’ils sont la solution à un problème
      grossier. (Comment rendre les mini-fourgonnettes plus masculines.) Mais
      tous les déchets ne sont pas mauvais. Maintenant que nous avons
      l’infrastructure pour le prendre en charge, compter les minutes de vos
      appels longue distance commence à sembler tatillon. Si vous avez les
      ressources, il est plus élégant de considérer tous les appels
      téléphoniques comme un seul genre de chose, peu importe où se trouve
      l’autre personne.
    </p>

    <p>
      Il y a de bons déchets et de mauvais déchets. Je m’intéresse aux bons
      déchets - ceux où, en dépensant plus, nous pouvons obtenir des conceptions
      plus simples. Comment allons-nous profiter des opportunités de gaspillage
      des cycles que nous obtiendrons du nouveau matériel plus rapide ?
    </p>

    <p>
      Le désir de vitesse est si profondément enraciné en nous, avec nos
      ordinateurs chétifs, qu’il faudra un effort conscient pour le surmonter.
      Dans la conception du langage, nous devrions rechercher consciemment des
      situations où nous pouvons échanger l’efficacité même pour la plus petite
      augmentation de commodité.
    </p>

    <p>
      La plupart des structures de données existent en raison de la vitesse. Par
      exemple, de nombreuses langues d’aujourd’hui ont à la fois des chaînes et
      des listes. Sur le plan sémantique, les chaînes sont plus ou moins un
      sous-ensemble de listes dans lesquelles les éléments sont des caractères.
      Alors, pourquoi avez-vous besoin d’un type de données distinct ? Vous ne
      le faites pas, vraiment. Les cordes n’existent que pour l’efficacité. Mais
      c’est boiteux d’encombrer les caractéristiques d’un langage avec des hacks
      pour que les programmes s’exécutent plus rapidement. Avoir des cordes dans
      un langage semble être un cas d’opération prématurée.
    </p>

    <p>
      Si nous pensons au cœur d’un langage comme à un ensemble d’axiomes, il est
      sûrement grossier d’avoir des axiomes supplémentaires qui n’ajoutent aucun
      pouvoir expressif, simplement par souci d’efficacité. L’efficacité est
      importante, mais je ne pense pas que ce soit la bonne façon de l’obtenir.
    </p>

    <p>
      La bonne façon de résoudre ce problème est de séparer la signification
      d’un programme des détails de la mise en œuvre. Au lieu d’avoir à la fois
      des listes et des chaînes, n’ayez que des listes, avec un moyen de donner
      au compilateur des conseils d’optimisation qui lui permettront de
      présenter des chaînes en octets contigus si nécessaire
      <sup id="fnref:1" role="doc-noteref"
        ><a href="#fn:1" class="footnote" rel="footnote">1</a></sup
      >.
    </p>

    <p>
      Étant donné que la vitesse n’a pas d’importance dans la majeure partie des
      programmes, vous n’aurez normalement pas besoin de vous préoccuper de ce
      genre de micro-gestion. Cela sera de plus en plus vrai au fur et à mesure
      que les ordinateurs deviendront plus rapides..
    </p>

    <p>
      Dire moins sur la mise en œuvre devrait également rendre les programmes
      plus flexibles. Les spécifications changent pendant qu’un programme est
      écrit, et c’est non seulement inévitable, mais aussi souhaitable.
    </p>

    <p>
      Le mot “essay” vient du verbe français “essayer”. Un essai, au sens
      original, est quelque chose que vous écrivez pour essayer de comprendre
      quelque chose. Cela se produit aussi dans les logiciels. Je pense que
      certains des meilleurs programmes étaient des essais, en ce sens que les
      auteurs ne savaient pas quand ils ont commencé exactement ce qu’ils
      essayaient d’écrire.
    </p>

    <p>
      Les hackers Lisp connaissent déjà l’intérêt d’être flexible avec les
      structures de données. Nous avons tendance à écrire la première version
      d’un programme pour qu’il fasse tout avec des listes. Ces versions
      initiales peuvent être si étonnamment inefficaces qu’il faut un effort
      conscient pour ne pas penser à ce qu’elles font, tout comme, pour moi au
      moins, manger un steak nécessite un effort conscient pour ne pas penser
      d’où il vient.
    </p>

    <p>
      Ce que les programmeurs dans cent ans chercheront, surtout, c’est un
      langage où vous pouvez assembler une version 1 incroyablement inefficace
      d’un programme avec le moins d’effort possible. Au moins, c’est ainsi que
      nous le décririons en termes actuels. Ce qu’ils diront, c’est qu’ils
      veulent un langage facile à programmer.
    </p>

    <p>
      Les logiciels inefficaces ne sont pas grossiers. Ce qui est grossier,
      c’est un langage qui oblige les programmeurs à faire un travail inutile.
      La gaspillage du temps du programmeur est la véritable inefficacité, et
      non le gaspillage du temps de la machine. Cela sera de plus en plus clair
      au fur et à mesure que les ordinateurs deviendront plus rapides.
    </p>

    <p>
      Je pense que se débarrasser des ficelles est déjà quelque chose à laquelle
      nous pourrions supporter de penser. Nous l’avons fait dans Arc, et cela
      semble être une victoire ; certaines opérations qui seraient difficiles à
      décrire comme expressions régulières peuvent être facilement décrites
      comme des fonctions récursives.
    </p>

    <p>
      Jusqu’où ira cet aplatissement des structures de données ? Je peux penser
      à des possibilités qui me choquent même, avec mon esprit
      consciencieusement large. Allons-nous nous débarrasser des tableaux, par
      exemple ? Après tout, ils ne sont qu’un sous-ensemble de tables de hachage
      où les clés sont des vecteurs entiers. Allons-nous remplacer les tables de
      hachage elles-mêmes par des listes?
    </p>

    <p>
      Il y a même plus de perspectives choquantes que cela. Logiquement, vous
      n’avez pas besoin d’avoir une notion distincte des nombres, car vous
      pouvez les représenter sous forme de listes : l’entier n pourrait être
      représenté sous la forme d’une liste de n éléments. Vous pouvez faire des
      maths de cette façon. C’est tout simplement insupportablement inefficace.
    </p>

    <p>
      Un langage de programmation pourrait-il aller jusqu’à se débarrasser des
      nombres en tant que type de données fondamental ? Je pose cette question
      moins comme une question sérieuse que comme une façon de jouer à la poule
      mouillée avec l’avenir. C’est comme le cas hypothétique d’une force
      irrésistible rencontrant un objet immobile - ici, une rencontre de mise en
      œuvre inimaginablement inefficace rencontrant des ressources
      inimaginablement grandes. Je ne vois pas pourquoi pas. L’avenir est assez
      long. S’il y a quelque chose que nous pouvons faire pour diminuer le
      nombre d’axiomes dans le langage de base, cela semblerait être le côté sur
      lequel parier à l’approche de l’infini. Si l’idée semble encore
      insupportable dans cent ans, peut-être qu’elle ne le sera pas dans mille
      ans.
    </p>

    <p>
      Juste pour être clair à ce sujet, je ne propose pas que tous les calculs
      numériques soient réellement effectués à l’aide de listes. Je propose que
      le langage de base, avant toute notation supplémentaire sur la mise en
      œuvre, soit défini de cette façon. En pratique, tout programme qui
      voudrait faire une quantité quelconque de mathématiques représenterait
      probablement des nombres en binaire, mais ce serait une optimisation, et
      ne ferait pas partie de la sémantique du langage de base.
    </p>

    <p>
      Entre l’application et le matériel. C’est aussi une tendance que nous
      voyons déjà se produire : de nombreux langages récents sont compilés en
      code d’octets. Bill Woods m’a dit un jour que, en règle générale, chaque
      couche d’interprétation coûte un facteur dix en vitesse. Ce coût
      supplémentaire vous fait gagner de la flexibilité.
    </p>

    <p>
      La toute première version d’Arc était un cas extrême de ce genre de
      lenteur à plusieurs niveaux, avec les avantages correspondants. Il
      s’agissait d’un interprète “métacirculaire” classique écrit sur Common
      Lisp, avec une certaine ressemblance familiale avec la fonction
      d’évaluation définie dans l’article original de Lisp de McCarthy. Le tout
      n’était que de quelques centaines de lignes de code, donc c’était facile à
      comprendre et à changer. Le Common Lisp que nous avons utilisé, CLisp,
      s’exécute lui-même sur un interpréteur de code octet. Nous avions donc ici
      deux niveaux d’interprétation, l’un d’eux (le premier) étonnamment
      inefficace, et le langage était utilisable. À peine utilisable, je
      l’avoue, mais utilisable.
    </p>

    <p>
      Écrire des logiciels en plusieurs couches est une technique puissante,
      même dans les applications. La programmation ascendante signifie
      l’écriture d’un programme sous la forme d’une série de couches, dont
      chacune sert de langage pour celle ci-dessus. Cette approche a tendance à
      produire des programmes plus petits et plus flexibles. C’est aussi la
      meilleure route vers ce Saint Graal, la réutilisabilité. Une langue est
      par définition réutilisable. Plus vous poussez votre application dans un
      langage permettant d’écrire ce type d’application, plus votre logiciel
      sera réutilisable.
    </p>

    <p>
      D’une manière ou d’une autre, l’idée de réutilisabilité s’est attachée à
      la programmation orientée objet dans les années 1980, et aucune preuve du
      contraire ne semble être en mesure de la secouer librement. Mais bien que
      certains logiciels orientés objet soient réutilisables, ce qui le rend
      réutilisable, c’est sa position ascendante, pas son orientation objet.
      Considérez les bibliothèques : elles sont réutilisables parce qu’elles
      sont du langage, qu’elles soient écrites dans un style orienté objet ou
      non.
    </p>

    <p>
      Je ne prédis pas la disparition de la programmation orientée objet, soit
      dit en passant. Bien que je ne pense pas qu’il ait grand-chose à offrir à
      de bons professionnels, sauf dans certains domaines spécialisés, il est
      irrésistible pour les grandes organisations. La programmation orientée
      objet offre un moyen durable d’écrire du code spaghetti. Il vous permet
      d’accréditer les programmes sous la forme d’une série de correctifs. Les
      grandes organisations ont toujours tendance à développer des logiciels de
      cette façon, et je m’attends à ce que cela soit aussi vrai dans cent ans
      qu’aujourd’hui.
    </p>

    <p>
      Tant que nous parlons de l’avenir, nous ferions mieux de parler de calcul
      parallèle, parce que c’est là que cette idée semble vivre. À tout moment,
      cela semble toujours être quelque chose qui va se produire à l’avenir.
    </p>

    <p>
      L’avenir le rattrapera-t-il un jour ? Les gens parlent du calcul parallèle
      comme de quelque chose d’imminent depuis au moins vingt ans, et cela n’a
      pas beaucoup affecté la pratique de la programmation jusqu’à présent. Ou
      n’est-ce pas ? Les concepteurs de puces doivent déjà y réfléchir, tout
      comme les gens qui essaient d’écrire des logiciels système sur des
      ordinateurs multi-CPU.
    </p>

    <p>
      La vraie question est la suivante : jusqu’où ira le parallélisme dans
      l’échelle de l’abstraction ? Dans cent ans, cela affectera-t-il même les
      programmeurs d’applications ? Ou est-ce quelque chose auquel les
      rédacteurs compilateurs pensent, mais qui est généralement invisible dans
      le code source des applications ?
    </p>

    <p>
      Une chose qui semble probable, c’est que la plupart des opportunités de
      parallélisme seront gaspillées. C’est un cas particulier de ma plus grande
      prédiction que la majeure partie de la puissance supplémentaire de
      l’ordinateur qui nous est donnée sera gaspillée. Je m’attends à ce que,
      comme pour la vitesse prodigieuse du matériel déséquilibré et, le
      parallélisme sera quelque chose qui sera disponible si vous le demandez
      explicitement, mais normalement pas utilisé. Cela implique que le genre de
      parallélisme que nous avons dans cent ans ne sera pas, sauf dans des
      applications spéciales, un parallélisme massif. Je m’attends à ce que pour
      les programmeurs ordinaires, il s’agira plutôt d’être en mesure de dériver
      des processus qui finissent tous par s’exécuter en parallèle.
    </p>

    <p>
      Et cela, comme demander des implémentations spécifiques de structures de
      données, sera quelque chose que vous ferez assez tard dans la vie d’un
      programme, lorsque vous essayez de l’optimiser. Les versions 1 ignoreront
      normalement tous les avantages à tirer du calcul parallèle, tout comme
      elles ignoreront les avantages à tirer de représentations spécifiques de
      données.
    </p>

    <p>
      Sauf dans les types spéciaux d’applications, le parallélisme n’imprégnera
      pas les programmes qui sont écrits dans cent ans. Ce serait une
      optimisation prématurée si c’était le cas.
    </p>

    <p>
      Combien de langages de programmation y aura-t-il dans cent ans ? Il semble
      y avoir un grand nombre de nouveaux langages de programmation ces derniers
      temps. Une partie de la raison en est que le matériel plus rapide a permis
      aux programmeurs de faire différents compromis entre la vitesse et la
      commodité, en fonction de l’application. S’il s’agit d’une véritable
      tendance, le matériel que nous aurons dans cent ans ne devrait que
      l’augmenter.
    </p>

    <p>
      Et pourtant, il n’y a peut-être que quelques langages largement utilisés
      en cent ans. Une partie de la raison pour laquelle je dis cela est
      l’optimisme : il semble que, si vous faisiez un très bon travail, vous
      pourriez créer un langage idéal pour écrire une version lente 1, et
      pourtant, avec les bons conseils d’optimisation au compilateur, vous
      donneriez également un code rapide si nécessaire. Donc, puisque je suis
      optimiste, je vais prédire que malgré l’énorme écart qu’ils auront entre
      l’efficacité acceptable et l’efficacité maximale, les programmeurs dans
      cent ans auront des langages qui peuvent couvrir la majeure partie de
      celui-ci.
    </p>

    <p>
      Au fur et à mesure que cet écart s’élargira, les profileurs deviendront de
      plus en plus importants. Peu d’attention est accordée au profilage
      maintenant. Beaucoup de gens semblent encore croire que la façon d’obtenir
      des applications rapides est d’écrire des compilateurs qui génèrent du
      code rapide. Au fur et à mesure que l’écart entre les performances
      acceptables et maximales s’élargit, il deviendra de plus en plus clair que
      la façon d’obtenir des applications rapides est d’avoir un bon guide de
      l’un à l’autre.
    </p>

    <p>
      Quand je dis qu’il n’y a peut-être que quelques langages, je n’inclue pas
      les “petits langages” spécifiques au domaine. Je pense que de tels
      langages embarqués sont une excellente idée, et je m’attends à ce qu’ils
      prolifèrent. Mais je m’attends à ce qu’ils soient écrits comme des peaux
      assez fines pour que les utilisateurs puissent voir le langage général en
      dessous.
    </p>

    <p>
      Qui concevra les langues du futur ? L’une des tendances les plus citées au
      cours des dix dernières années a été l’essor des langages open source
      comme Perl, Python et Ruby. La conception du langage est prise en charge
      par des hackers. Les résultats jusqu’à présent sont désordonnés, mais
      encourageants. Il y a des idées incroyablement nouvelles à Perl, par
      exemple. Beaucoup sont incroyablement mauvais, mais c’est toujours le cas
      des efforts ambitieux. À son taux de mutation actuel, Dieu sait en quoi
      Perl pourrait évoluer dans cent ans.
    </p>

    <p>
      Il n’est pas vrai que ceux qui ne peuvent pas faire, enseignent (certains
      des meilleurs hackers que je connaisse sont des professeurs), mais il est
      vrai qu’il y a beaucoup de choses que ceux qui enseignent ne peuvent pas
      faire. La recherche impose des restrictions contraignantes liées à la
      caste. Dans n’importe quel domaine académique, il y a des sujets sur
      lesquels il est acceptable de travailler et d’autres qui ne le sont pas.
      Malheureusement, la distinction entre les sujets acceptables et interdits
      est généralement basée sur la façon dont le travail semble intellectuel
      lorsqu’il est décrit dans les documents de recherche, plutôt que sur
      l’importance qu’il est pour obtenir de bons résultats. Le cas extrême est
      probablement la littérature ; les personnes qui étudient la littérature
      disent rarement quoi que ce soit qui serait de la moindre utilité pour
      ceux qui la produisent.
    </p>

    <p>
      Bien que la situation soit meilleure dans les sciences, le chevauchement
      entre le genre de travail que vous êtes autorisé à faire et le genre de
      travail qui donne de bons langages est péniblement petit. (Olin Shivers
      s’est exprimé de manière très éloquente à ce sujet.) Par exemple, les
      types semblent être une source inépuisable d’articles de recherche, malgré
      le fait que le typage statique semble exclure les vrais macros - sans
      lesquelles, à mon avis, aucun langage ne vaut la peine d’être utilisé.
    </p>

    <p>
      La tendance n’est pas seulement vers les langages développés en tant que
      projets open source plutôt que “recherche”, mais aussi vers les langages
      conçus par les programmeurs d’applications qui ont besoin de les utiliser,
      plutôt que par les rédacteurs de compilateurs. Cela semble être une bonne
      tendance et je m’attends à ce qu’elle se poursuive.
    </p>

    <p>
      Contrairement à la physique dans cent ans, qui est presque nécessairement
      impossible à prédire, il peut être possible en principe de concevoir un
      langage maintenant qui plairait aux utilisateurs dans cent ans.
    </p>

    <p>
      Une façon de concevoir un langage est de simplement écrire le programme
      que vous aimeriez pouvoir écrire, qu’il y ait un compilateur qui peut le
      traduire ou du matériel qui peut l’exécuter. Lorsque vous faites cela,
      vous pouvez assumer des ressources illimitées. Il semble que nous devrions
      être en mesure d’imaginer des ressources illimitées aussi bien aujourd’hui
      qu’en cent ans.
    </p>

    <p>
      Quel programme aimerait-on écrire ? Quel que soit le moins de travail.
      Sauf que pas tout à fait : tout ce qui serait le moins fonctionnerait si
      vos idées sur la programmation n’étaient pas déjà influencées par les
      langages auxquels vous êtes actuellement habitué.es. Une telle influence
      peut être si omniprésente qu’il faut beaucoup d’efforts pour la surmonter.
      On pourrait penser qu’il serait évident pour des créatures aussi
      paresseuses que nous comment exprimer un programme avec le moins d’effort.
      En fait, nos idées sur ce qui est possible ont tendance à être si limitées
      par le langage que nous pensons que les formulations plus faciles de
      programmes semblent très surprenantes. C’est quelque chose que vous devez
      découvrir, pas quelque chose dans lequel vous vous enfoncez naturellement.
    </p>

    <p>
      Une astuce utile ici est d’utiliser la longueur du programme comme une
      approximation de la quantité de travail qu’il est à écrire. Pas la
      longueur des caractères, bien sûr, mais la longueur des éléments
      syntaxiques distincts - fondamentalement, la taille de l’arbre d’analyse.
      Il n’est peut-être pas tout à fait vrai que le programme le plus court est
      le moins de travail à écrire, mais il est assez proche pour que vous soyez
      mieux de viser la cible solide de la brièveté que le flou, à proximité de
      l’un des moins de travail. Ensuite, l’algorithme de conception du langage
      devient : regardez un programme et demandez, y a-t-il un moyen plus court
      d’écrire ceci ?
    </p>

    <p>
      En pratique, les programmes d’écriture dans une langue imaginaire
      centenaire fonctionneront à des degrés divers en fonction de votre
      proximité avec le noyau. Triez les routines que vous pouvez écrire
      maintenant. Mais il serait difficile de prédire maintenant quels types de
      bibliothèques pourraient être nécessaires dans cent ans. On peut supposer
      que de nombreuses bibliothèques seront pour des domaines qui n’existent
      même pas encore. Si SETI@home fonctionne, par exemple, nous aurons besoin
      de bibliothèques pour communiquer avec les extraterrestres. À moins bien
      sûr qu’ils ne soient suffisamment avancés pour qu’ils communiquent déjà en
      XML.
    </p>

    <p>
      À l’autre extrême, je pense que vous pourriez être en mesure de concevoir
      le langage de base aujourd’hui. En fait, certains pourraient faire valoir
      qu’il a déjà été principalement conçu en 1958.
    </p>

    <p>
      Si le langage centenaire était disponible aujourd’hui, voudrions-nous y
      programmer ? Une façon de répondre à cette question est de regarder en
      arrière. Si les langages de programmation actuels avaient été disponibles
      en 1960, quelqu’un aurait-il voulu les utiliser ?
    </p>

    <p>
      D’une certaine manière, la réponse est non. Les langues d’aujourd’hui
      supposent une infrastructure qui n’existait pas en 1960. Par exemple, un
      langage dans lequel l’indentation est importante, comme Python, ne
      fonctionnerait pas très bien sur les terminaux d’imprimante. Mais en
      mettant de tels problèmes de côté - en supposant, par exemple, que les
      programmes étaient tout simplement écrits sur papier - les programmeurs
      des années 1960 auraient-ils aimé écrire des programmes dans les langues
      que nous utilisons maintenant ?
    </p>

    <p>
      Je pense que c’est le cas. Certains des moins imaginatifs, qui avaient des
      faits d’art des premières langues intégrés dans leurs idées de ce qu’était
      un programme, auraient peut-être eu des problèmes. (Comment pouvez-vous
      manipuler les données sans faire de l’arithmétique des pointeurs ? Comment
      pouvez-vous mettre en œuvre des organigrammes sans gotos ?) Mais je pense
      que les programmeurs les plus intelligents n’auraient eu aucun mal à tirer
      le meilleur parti des langages d’aujourd’hui, s’ils les avaient eu.
    </p>

    <p>
      Si nous avions le langage centenaire maintenant, cela ferait au moins un
      excellent pseudocode. Que diriez-vous de l’utiliser pour écrire des
      logiciels ? Étant donné que le langage centenaire devra générer du code
      rapide pour certaines applications, il pourrait vraisemblablement générer
      un code suffisamment efficace pour fonctionner de manière acceptable sur
      notre matériel. Nous devrons peut-être donner plus de conseils
      d’optimisation que les utilisateurs dans cent ans, mais cela pourrait
      toujours être une victoire nette.
    </p>

    <p>
      Maintenant, nous avons deux idées qui, si vous les combinez, suggèrent des
      possibilités intéressantes : (1) le langage centenaire pourrait, en
      principe, être conçu aujourd’hui, et (2) un tel langage, s’il existait,
      pourrait être bon à programmer aujourd’hui. Quand vous voyez ces idées
      présentées comme ça, il est difficile de ne pas penser, pourquoi ne pas
      essayer d’écrire la langue centenaire maintenant ?
    </p>

    <p>
      Lorsque vous travaillez sur la conception du langage, je pense qu’il est
      bon d’avoir une telle cible et de la garder consciemment à l’esprit.
      Lorsque vous apprenez à conduire, l’un des principes qu’ils vous
      enseignent est d’aligner la voiture non pas en alignant le capot avec les
      rayures peintes sur la route, mais en visant un moment donné dans la
      distance. Même si tout ce dont vous vous souciez, c’est de ce qui se passe
      dans les dix prochains pieds, c’est la bonne réponse. Je pense que nous
      devrions faire la même chose avec les langages de programmation
    </p>

    <div class="footnotes" role="doc-endnotes">
      <ol>
        <li id="fn:1" role="doc-endnote">
          <p>
            Je crois que Lisp Machine Lisp a été le premier langage à incarner
            le principe selon lequel les déclarations (à l’exception de celles
            des variables dynamiques) n’étaient que des conseils d’optimisation
            et ne changeraient pas la signification d’un programme correct.
            Common Lisp semble avoir été le premier à l’indiquer
            explicitement. <a
              href="#fnref:1"
              class="reversefootnote"
              role="doc-backlink"
              >&#8617;</a
            >
          </p>
        </li>
      </ol>
    </div>
  </body>
</html>
